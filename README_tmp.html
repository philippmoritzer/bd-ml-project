<!DOCTYPE html>
<html>
<head>
<title>README.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>
<link rel="stylesheet" href="file:///Users/philippmoritzer/Documents/Hochschule/Big%20Data%20%26%20Machine%20Learning/project/docs/css/markdown-pdf.css" type="text/css">
<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="building-visualizing-and-classifying-a-nosql-time-series-data-store-using-influxdb2-python-and-grafana">Building, visualizing and classifying a NoSQL time series data store using InfluxDB2, Python and Grafana</h1>
<center>
</center><table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Author:</td>
<td>Philipp Moritzer</td>
</tr>
<tr>
<td></td>
<td>5034255</td>
</tr>
<tr>
<td></td>
<td>pmoritzer@stud.hs-bremen.de</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>Supervisor:</td>
<td>Prof. Dr.-Ing. Uta Bohnebeck</td>
</tr>
<tr>
<td></td>
<td>uta.bohnebeck@hs-bremen.de</td>
</tr>
<tr>
<td></td>
<td>Hochschule Bremen</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>Submission:</td>
<td>31st July 2022</td>
</tr>
</tbody>
</table>

<div style="page-break-after: always;"></div>
<h1 id="table-of-contents">Table of contents</h1>
<ul>
<li><a href="#building-visualizing-and-classifying-a-nosql-time-series-data-store-using-influxdb2-python-and-grafana">Building, visualizing and classifying a NoSQL time series data store using InfluxDB2, Python and Grafana</a></li>
<li><a href="#table-of-contents">Table of contents</a></li>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#fundamentals">Fundamentals</a>
<ul>
<li><a href="#nosql-basics">NoSQL basics</a></li>
<li><a href="#nosql-vs-relational-databases">NoSQL vs Relational Databases</a></li>
<li><a href="#time-series-databases">Time Series Databases</a></li>
<li><a href="#why-use-a-time-series-database">Why use a time series database</a></li>
<li><a href="#influxdb-basics">InfluxDB basics</a>
<ul>
<li><a href="#flux-query-language">Flux Query Language</a></li>
<li><a href="#influxdb-vs-timescale-vs-prometheus">InfluxDB vs Timescale vs Prometheus</a></li>
</ul>
</li>
<li><a href="#naive-bayes-classification">Naive Bayes Classification</a></li>
</ul>
</li>
<li><a href="#tutorial">Tutorial</a>
<ul>
<li><a href="#goals">Goals</a></li>
<li><a href="#the-data---movebank-animal-tracking">The data - Movebank: Animal tracking</a></li>
<li><a href="#prerequisites">Prerequisites</a></li>
<li><a href="#spinning-up-the-composition">Spinning up the composition</a>
<ul>
<li><a href="#docker-compose">docker-compose</a></li>
</ul>
</li>
<li><a href="#setting-up-influxdb">Setting up InfluxDB</a></li>
<li><a href="#writing-the-client-application">Writing the client application</a>
<ul>
<li><a href="#setting-up-the-environment">Setting up the environment</a></li>
<li><a href="#setting-up-the-application">Setting up the application</a></li>
<li><a href="#implementing-functionality">Implementing functionality</a></li>
</ul>
</li>
<li><a href="#setting-up-grafana">Setting up Grafana</a>
<ul>
<li><a href="#defining-influxdb-as-a-data-source">Defining InfluxDB as a data source</a></li>
<li><a href="#creating-a-dashboard">Creating a dashboard</a></li>
</ul>
</li>
<li><a href="#visualizing-and-analyising-the-data">Visualizing and analyising the data</a>
<ul>
<li><a href="#dashboard-variables">Dashboard variables</a></li>
<li><a href="#geomap--heatmap">Geomap &amp; Heatmap</a></li>
<li><a href="#latitude-over-time">Latitude over time</a></li>
<li><a href="#classification">Classification</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#summary">Summary</a>
<ul>
<li><a href="#result">Result</a></li>
<li><a href="#conclusion">Conclusion</a></li>
<li><a href="#outlook">Outlook</a></li>
<li><a href="#repository-and-sample-project">Repository and sample project</a></li>
<li><a href="#demo">Demo</a></li>
</ul>
</li>
<li><a href="#sources">Sources</a></li>
</ul>
<h1 id="introduction">Introduction</h1>
<p>Big Data, IoT, and analytics, and as a result, new methods of storing this fluid data have emerged. Almost all streaming data, particularly IoT data, but also real-time analytics and server and application monitoring, has a time stamp and thus is time series data. This project will go on to demonstrate the differences between traditional databases and NoSQL (time series) databases, why they are used, and how to build a project on top of them. The completed project stores, visualizes, and classifies data using InfluxDB2, Python, and Grafana using time-stamped CSV data containing bird migration data as a time analytics approach.</p>
<h1 id="fundamentals">Fundamentals</h1>
<h2 id="nosql-basics">NoSQL basics</h2>
<p>NoSQL is a different approach to database design that excludes traditional relational database management systems. While relational database systems attempt to abstract the underlying data structure, NoSQL databases are more data-specific, which should make them more efficient for this specific data. They are intended to implement data structures in a manner that is more closely aligned with the target system, whereas traditional relational databases cannot be structured in this sort of way. The motivation for using NoSQL databases is that they do not require the use of a predefined schema, resulting in a simpler design, horizontal scaling, and greater control over data availability.
Because NoSQL distributes its data, it must adhere to the CAP theorem, which states that only two of the three following attributes can be achieved: consistency, availability, and partition tolerance. Depending on the application to implement and the needs of the use cases, different databases prioritize consistency over availability, while others prioritize availability over consistency. [1, 2, 3]</p>
<h2 id="nosql-vs-relational-databases">NoSQL vs Relational Databases</h2>
<p>NoSQL and relational databases both have the same basic goals: to store and retrieve data, as well as to coordinate changes. The distinction is that NoSQL databases abandon some of the capabilities of relational databases in order to increase scalability. NoSQL databases, in particular, typically have much simpler coordination capabilities than traditional relational systems, sometimes even none at all. NoSQL databases typically remove all or most of the SQL query language, as well as a complex optimizer required for SQL to be useful.
The benefit of the tradeoff is that NoSQL databases are often very simple and can handle unstructured data, resulting in higher scalability in the best case. This has the disadvantage of losing overview by storing a large amount of unstructured and unformatted data, and optimization is in the hands of the developr rather than the optimizer when using relational databases. [4]</p>
<h2 id="time-series-databases">Time Series Databases</h2>
<p>A time series is a grouping of values organized by time. Stock prices, for example, may fluctuate throughout the day as trades are executed, or a weather sensor may record atmospheric temperatures every minute. Any event that is recorded over time, whether on a regular or irregular basis, is considered time series data. A time series database is intended to make time series data retrieval and statistical analysis easier. While time series data like orders, shipments, and logs have long been stored in relational databases, the data sizes and volumes were frequently insignificant. As data grew faster and larger, special-purpose databases became necessary. Time series databases, for example, address the needs of increasing, high-velocity data volumes from IoT, event, and application logs. These are frequently write-intensive workloads. As a result, memory buffering is frequently used to support fast writes and reads in time series databases. Looking at the CAP Theorem, InfluxDB focuses on either CP or AP but tries to find a middle ground between the two. [3, 5]</p>
<h2 id="why-use-a-time-series-database">Why use a time series database</h2>
<p>It is necessary to consider the problems that time series databases attempt to solve. IoT devices and real-time analytics generate a large amount of data, and with the increasing amount of data produced with a time stamp, there must be a way to deal with this. Regular time series data, such as measurements taken every 10 seconds, and irregular data, such as API requests, are the two types of time series data. A modern time series database should be capable of handling both types of data. Time series databases are designed to deal with problems that arise with these high volume measurement data, and as a result, they solve three major characteristics with the data they use: exceptionally high volume, natural time order, and the entire set of data being more valuable than individual records. When these issues arise in the development of an application or system, it is recommended that a time series database is used. They concentrate on optimizing frequent writes, merging data, and constructing sums and averages in order to treat the data as a whole and store combined data beyond the retention period. They also provide optimized query languages for handling data based on the use case. [7]
Consider using a traditional SQL database to store time series data. In general, it is possible, but problems arise when a certain data threshold is reached. It is common in time series databases to set a retention period so that data from a specific period is stored as a cumulation. Using the same logic in SQL, there will eventually have to be the same number of deletes as inserts, a use case that a traditional database system is not designed to handle well. It is also possible to shard a traditional database to scale across systems, but this requires more application code to be written. Time series databases and its libraries, such as InfluxDB and its python library, support this out of the box. [8]</p>
<h2 id="influxdb-basics">InfluxDB basics</h2>
<p>According to https://db-engines.com/, InfluxDB is the most popular NoSQL time series database created by InfluxData. Its primary application is handling massive amounts of time-stamped data. Collecting IoT data is a common example because every data set in IoT is time-based. However, it is frequently used for analytics as well as IoT data, for example, in this project time-stamped data for bird migration will be handled using InfluxDB2.
The first version of InfluxDB came out in 2013 and the 1.x version is still commonly used. However, in 2020 InfluxDB was released as a stable version and is the way to go. It features a new query language, which will be explained in the next section, as well as a standalone binary with a graphical web interface to explore data. [9, 10]</p>
<h3 id="flux-query-language">Flux Query Language</h3>
<p>InfluxDB includes a query language called Flux for querying, analyzing, and acting on data.
Flux queries perform various operations, but in general, a query is constructed as follows:</p>
<pre class="hljs"><code><div>from(bucket) 
    |&gt; range(<span class="hljs-keyword">start</span>: x, <span class="hljs-keyword">stop</span>: y) 
    |&gt; <span class="hljs-comment">#filteroptions</span>
</div></code></pre>
<p>The pipe symbol <code>|&gt;</code> marks pipe forward data and therefore every function or expression that follows after that symbol takes the former expression as an input.</p>
<p>Typically, a bucket, which is a store for time series data in InfluxDB, will be chosen first to serve as a source. A time range is required for a flux query because queries without a time window are resource-intensive; therefore, it is up to the user to specify a common time-window that complements the data required. When only these fields are specified in the query, the result is an output table with a timestamp as the individual identifier key and the measurements. Following that, one can filter the data based on their requirements, such as after a field. There are also many built-in functions that can be used to reduce, sum up, interpret, or map data. This can be used to prepare the data for visualization or other purposes (e.g. classification, machine learning). As an example, consider the following query that filters data in a time range of 12 hours and selects the fields <code>lat</code> and <code>lon</code> as location data and with the measurement tag <code>location</code>:</p>
<pre class="hljs"><code><div>from(bucket: "bucket")
    |&gt; range(<span class="hljs-keyword">start</span>: <span class="hljs-number">2021</span><span class="hljs-number">-01</span><span class="hljs-number">-01</span>T00:<span class="hljs-number">00</span>:<span class="hljs-number">00</span>Z, <span class="hljs-keyword">stop</span>: <span class="hljs-number">2021</span><span class="hljs-number">-01</span><span class="hljs-number">-01</span>T12:<span class="hljs-number">00</span>:<span class="hljs-number">00</span>Z)
    |&gt; filter(fn: (r) =&gt; r._measurement == <span class="hljs-string">"location"</span> <span class="hljs-keyword">and</span> r._field == <span class="hljs-string">"lat"</span> <span class="hljs-keyword">and</span> r.lat == <span class="hljs-string">"lat"</span>)
</div></code></pre>
<p>[11, 12]</p>
<h3 id="influxdb-vs-timescale-vs-prometheus">InfluxDB vs Timescale vs Prometheus</h3>
<p>Prometheus and TimescaleDB serve a similar purpose than InfluxDB by being time series databases. While InfluxDB is the most used time series database according to (https://db-engines.com/de/ranking/time+series+dbms, 10.07.2022, 18:06) the other two databases are very commonly used. The question that arises is why alternatives to InfluxDB exist and how the other candidates differ.</p>
<p>Prometheus:</p>
<ul>
<li>Uses its own query language PromQL</li>
<li>More features for monitoring purposes</li>
<li>Less support for real-time analytics or machine learning</li>
<li>Only milisecond timestamps vs InfluxDB's nanoseconds</li>
<li>Less resource usage</li>
</ul>
<p>TimescaleDB:</p>
<ul>
<li>Based on PostgreSQL</li>
<li>Uses SQL as query language</li>
<li>Relational data model</li>
<li>Inferior performance to InfluxDB</li>
</ul>
<p>Applications running in the cloud infrastructure often use the vendor's own database. For AWS it is called Amazon Timestream, for Azure Azure Time Series Insights. They are in these type of compositions because it centralises the management to the vendor infrastructure. [13, 14, 15]</p>
<h2 id="naive-bayes-classification">Naive Bayes Classification</h2>
<p>Based on the input, the Naive Bayes classification is described as a probabilistic classifier that should be able to predict a probability. It is based on the Bayes Theorem:</p>
<p>$$ P(A|B) = {P(A|B)<img class="emoji" alt="stuck_out_tongue" src="data:image/png;base64,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" />(A) \over P(B) } $$</p>
<p>A distribution over a set of classes is calculated given an observation of an input. After that, the classifier can be trained to determine which class has the highest probability. Consider the the following:</p>
<p>$$ P(Class:|:Field) $$</p>
<p>Given enough training data the probability can be predicted based on a given field. A simplified example would be that if a bird is in the northern hemisphere in the winter we could predict which season of the year it, e.g.:</p>
<p>$$ P(Winter | Tropes) = 0.7 $$</p>
<p>In words, if a data point is in the tropes a prediction with a certain probability (e.g. 0.7) that the current season is winter can be made.
This type of classification can be performed using the Flux query language.</p>
<p>[11, 16, 17]</p>
<h1 id="tutorial">Tutorial</h1>
<h2 id="goals">Goals</h2>
<p>The purpose of this project is to process a large amount of time series data. The data is stored using a NoSQL approach with InfluxDB. A Grafana Dashboard is constructed to visualize the data, and appropriate visualisation tools are employed. The data will be parsed using
Python and processed to InfluxDB using functional programming in combination with the Python
client library provided by InfluxDB. Using Flux a classification will be done on the existing dataset.</p>
<h2 id="the-data---movebank-animal-tracking">The data - Movebank: Animal tracking</h2>
<p>The data used in this example was obtained from the following location: https://www.kaggle.com/datasets/pulkit8595/movebank-animal-tracking (visited: 11.07.2022, 19:31) The data contains a set of measurements in which various birds were fitted with GPS-Sensors to determine their location using geodata. Each measurement includes an event identifier, a timestamp, a location (latitude and longitude), a local identifier, and study data. Some fields are left blank or share the same value on every record (visible, manually-marked-outlier, individual-taxon-identifier). The data set contains 89868 individual records tracking 49 Birds over a 7-year period (2009-2015).</p>
<h2 id="prerequisites">Prerequisites</h2>
<ul>
<li>Python 3.10 (with pip3) https://www.python.org/downloads/</li>
<li>Docker (20+, Version 20.10.13 is used for this project) https://docs.docker.com/get-docker/</li>
<li>docker-compose installed (1.20+, Version 1.29.2 is used for this project) https://docs.docker.com/compose/install/</li>
</ul>
<p>It is advised to use the most recent versions.
The following commands can be used to determine whether the requirements have been met:</p>
<pre class="hljs"><code><div>$ python3 --version
<span class="hljs-comment"># Output: Python 3.10.*</span>
$ docker -version
<span class="hljs-comment"># Output: Docker version 20.10.13, build a224086</span>
$ docker-comopse --version
<span class="hljs-comment"># Output: docker-compose version 1.29.2, build 5becea4c</span>
</div></code></pre>
<h2 id="spinning-up-the-composition">Spinning up the composition</h2>
<h3 id="docker-compose">docker-compose</h3>
<p>There is no need to install InfluxDB or Grafana locally to quickly spin up the environment. Although it is possible to follow along using locally installed or remotely hosted instances, docker-compose makes it easier to spin up the services. If no project root has yet been created, create a new folder for the project and add the following <code>docker-compose.yml</code> file:</p>
<pre class="hljs"><code><div><span class="hljs-attr">version:</span> <span class="hljs-string">"3.9"</span>

<span class="hljs-attr">services:</span>
  <span class="hljs-attr">influxdb:</span>
    <span class="hljs-attr">image:</span> <span class="hljs-string">influxdb:2.2.0-alpine</span>
    <span class="hljs-attr">container_name:</span> <span class="hljs-string">influxdb</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"8083:8083"</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"8086:8086"</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"8090:8090"</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"2003:2003"</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">./data/influxdb:/var/lib/influxdb2</span>
    <span class="hljs-attr">networks:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">network1</span>

  <span class="hljs-attr">grafana:</span>
    <span class="hljs-attr">image:</span> <span class="hljs-string">grafana/grafana:7.5.16</span>
    <span class="hljs-attr">container_name:</span> <span class="hljs-string">grafana</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"3000:3000"</span>
    <span class="hljs-attr">user:</span> <span class="hljs-string">"0"</span>
    <span class="hljs-attr">links:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">influxdb</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">./data/grafana:/var/lib/grafana</span>
    <span class="hljs-attr">networks:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">network1</span>

<span class="hljs-attr">networks:</span>
  <span class="hljs-attr">network1:</span>
</div></code></pre>
<p>Volumes are used by both InfluxDB and Grafana. The next step is to make sure that a directory called <code>data/</code> is created in the project root directory, which contains two empty subdirectories called <code>grafana/</code> and <code>influxdb/</code>. These directories will be filled to persist data when using these applications. Later in the tutorial, they will be filled in. This is how the project should be structured now:</p>
<pre class="hljs"><code><div>- &lt;project-root&gt; 
  - data/
    - grafana/
    - influxdb/
  docker-compose.yml
</div></code></pre>
<p>Also a network is added in the <code>docker-compose.yml</code> file so the Python application is able to communicate with the services on the same network later on when using Docker.
Docker-compose is used to spin up a local instance of InfluxDB and Grafana. To start both services, following command has to be entered:</p>
<pre class="hljs"><code><div>docker-compose up
</div></code></pre>
<blockquote>
<p>Note for Unix-Users: If the Grafana-Container fails to start due to permission errors, the permission of the ./data/grafana Folder should be changed to 472 and made sure it is owned by the account using it.</p>
</blockquote>
<p>The InfluxDB exposed the Port 8086 for the web interface and should now be reachable locally on <code>http://localhost:8086/</code>:</p>
<p>InfluxDB on localhost:8086
<img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/docker-compose-setup/influx-welcome.png" alt="alt text" title="Influx running on localhost:8086"></p>
<p>While Grafana uses Port 3000 for its web interface and should be reachable by typint <code>http://localhost:3000</code> in a browser:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/docker-compose-setup/grafana-welcome.png" alt="alt text" title="Grafana running on localhost:3000"> <em>Grafana on localhost:3000</em></p>
<h2 id="setting-up-influxdb">Setting up InfluxDB</h2>
<p>To access the InfluxDB web interface, <code>localhost:8086</code> has to be accessed. The 'Get Started' button has to be pressed to begin the setup procedure. The setup then asks for a login, password, organization name, and an initial bucket name in the next stage. The password for <code>root</code> is <code>password</code>, and the initial organization name is my tag <code>pmoritzer</code>. The bucket name must be set initially, but the bucket is not needed because the data processing unit python application will create a bucket dynamically in the future. The information should be saved because it will be required to log in to the web interface later on and the organization name will serve as an identifier in the client application.</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/influxdb-setup/initial-account.png" alt="alt text"><em>First setup step for InfluxDB</em></p>
<p>Because we want to inject data manually, simply select &quot;Configure later&quot; in the following step.
The final step in setting up InfluxDB is to obtain the necessary API token.
To do so, select the Data tab in the left sidebar, followed by the &quot;API Tokens&quot; tab in the tab view on top. A window will appear when you click on root's Token including the API Token. To access the InfluxDB from an external application, the token should be saved somewhere. Because security is not an issue in this proof of concept, we can use the root token; however, in a production environment, separate users with access rights should be set up.</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/influxdb-setup/api-token-1.png" alt="alt text"><em>InfluxDB API-Token 1/2</em></p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/influxdb-setup/api-token-2.png" alt="alt text"><em>InfluxDB API-Token 2/2</em></p>
<h2 id="writing-the-client-application">Writing the client application</h2>
<h3 id="setting-up-the-environment">Setting up the environment</h3>
<p>First, environment variables that will be required to connect to the local instance of InfluxDB will be set. Using an environment file, a folder called <code>&lt;project-root&gt;/env/</code> will be created within the project root directory. A file called <code>env.app</code> will be created that looks as follows:</p>
<pre class="hljs"><code><div><span class="hljs-attr">INFLUX_URL</span>=<span class="hljs-string">http://influxdb:8086</span>
<span class="hljs-attr">INFLUX_TOKEN</span>=<span class="hljs-string">&lt;root-api-token&gt;</span>
<span class="hljs-attr">INFLUX_ORG</span>=<span class="hljs-string">&lt;org-name&gt;</span>
</div></code></pre>
<p>Replace the <code>INFLUX_TOKEN</code> property to equal the generated API-Token from the setup and the <code>INFLUX_ORG</code> properties with the organization name set. The data processing client application is able to connect to the database by loading these definded properties.</p>
<h3 id="setting-up-the-application">Setting up the application</h3>
<p>A file called <code>main.py</code> is created in the project's root directory that will serve as an entrypoint for the client application. First, a simple output is done to check whether the application works.</p>
<pre class="hljs"><code><div><span class="hljs-keyword">print</span> (<span class="hljs-string">"Hello World"</span>)
</div></code></pre>
<p><em>main.py</em></p>
<pre class="hljs"><code><div>$ python3 main.py
<span class="hljs-comment"># Output: Hello World</span>
</div></code></pre>
<p>For the dependencies a <code>requirements.txt</code>file is created in the project's root directory with following content to install the python client library for InfluxDB using pip. To make sure they are locally available, the following command has to be executed:</p>
<pre class="hljs"><code><div><span class="hljs-meta">influxdb-client</span> =<span class="hljs-string">= 1.29.0</span>
</div></code></pre>
<pre class="hljs"><code><div>$ pip3 install -r requirements.txt
</div></code></pre>
<p>Next, the application is going to be dockerized. To do so, a <code>Dockerfile</code> will be created. Docker ensures that the application can run with the dependencies defined regardless of the system's environment.</p>
<pre class="hljs"><code><div><span class="hljs-comment"># syntax=docker/dockerfile:1</span>
<span class="hljs-keyword">FROM</span> python:<span class="hljs-number">3.10</span>.<span class="hljs-number">4</span>-slim-bullseye

<span class="hljs-keyword">WORKDIR</span><span class="bash"> /app</span>

<span class="hljs-keyword">COPY</span><span class="bash"> requirements.txt requirements.txt</span>

<span class="hljs-keyword">RUN</span><span class="bash"> pip3 install -r requirements.txt</span>

<span class="hljs-keyword">COPY</span><span class="bash"> . .</span>

<span class="hljs-keyword">CMD</span><span class="bash"> [<span class="hljs-string">"python3"</span>,<span class="hljs-string">"-u"</span>,<span class="hljs-string">"./main.py"</span>]</span>
</div></code></pre>
<p>Create a <code>run.sh</code> script (or <code>.bat</code> for Windows Users) that executes following commands in a row:</p>
<pre class="hljs"><code><div>$ docker build --no-cache -t influxdb-sample .
$ docker network create project_network1
$ docker run --network=project_network1 --env-file ./env/env.app influxdb-sample
</div></code></pre>
<p>This script builds this application into a Docker Image, creates a network and starts the container while making sure it can communicate with the services on the same network, <code>network1</code>.</p>
<pre class="hljs"><code><div>$ ./run.sh
<span class="hljs-comment"># Output: Hello World</span>
</div></code></pre>
<p>Every time the the application needs to be started locally locally, the <code>run.sh</code> script can be run.</p>
<h3 id="implementing-functionality">Implementing functionality</h3>
<p>First a function for connecting to InfluxDB will be implemented. A a folder <code>app/</code> is created including a file <code>connect_to_influx.py</code>. The content of the file will be as follows:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> influxdb_client <span class="hljs-keyword">import</span> InfluxDBClient

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">connect_to_influxdb</span><span class="hljs-params">(url, token, org, retries=<span class="hljs-number">10</span>, tried=<span class="hljs-number">0</span>)</span> -&gt; InfluxDBClient:</span>
    print(<span class="hljs-string">"Connecting to InfluxDB on "</span> + url)
    client = InfluxDBClient(url=url, token=token, org=org, debug=<span class="hljs-literal">True</span>)
    health = client.health()

    <span class="hljs-keyword">if</span> health.status == <span class="hljs-string">"pass"</span>:
        print(<span class="hljs-string">"Connected to InfluxDB on "</span> + url + <span class="hljs-string">"/"</span>)
        <span class="hljs-keyword">return</span> client
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">if</span> tried &lt; retries:            
            print(<span class="hljs-string">"Connection to {} refused, retrying {} times."</span>.format(url, (retries-tried)))     
            tried += <span class="hljs-number">1</span>   
            time.sleep(<span class="hljs-number">10</span>)
            <span class="hljs-keyword">return</span> connect_to_influxdb(url, token, org, retries, tried)
        <span class="hljs-keyword">else</span>:            
            <span class="hljs-keyword">raise</span> ConnectionError(<span class="hljs-string">"Connection to influxdb failed."</span>)
</div></code></pre>
<p>The file contains a function that returns an InfluxDBClient connection object. The method invokes the constructor with the required information (URL, API-Token, organisation). If the connection is successful and healthy, this custom wrapper method returns the InfluxDBClient object. If it is not, it tries to connect to the given InfluxDB instance as many times as specified. If it fails, the application will exit with a connection error.</p>
<p>The application logic for writing the bird-migration sample data to InfluxDB must now be implemented. First, the database connection function that was just implemented is imported, as well as any other imports required for this logic. Among these are the InfluxDB client library, csv for handling CSV data, and the <code>rx</code> functional programming library.</p>
<pre class="hljs"><code><div><span class="hljs-keyword">from</span> app.connect_to_influx <span class="hljs-keyword">import</span> connect_to_influxdb

<span class="hljs-keyword">from</span> influxdb_client <span class="hljs-keyword">import</span> Point, WriteOptions

<span class="hljs-keyword">from</span> csv <span class="hljs-keyword">import</span> DictReader
<span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> OrderedDict
<span class="hljs-keyword">from</span> decimal <span class="hljs-keyword">import</span> Decimal
<span class="hljs-keyword">import</span> os

<span class="hljs-comment">#import rx for functional programming</span>
<span class="hljs-keyword">import</span> rx <span class="hljs-comment"># functional programming library</span>
<span class="hljs-keyword">from</span> rx <span class="hljs-keyword">import</span> operators
</div></code></pre>
<p>The parameters for connecting to the database will be loaded using environment variables in the following step. It must be ensured that the application is started using Docker with env-files. The script will fail if these environment variables are not specified.</p>
<pre class="hljs"><code><div>url = os.environ[<span class="hljs-string">'INFLUX_URL'</span>] <span class="hljs-keyword">or</span> <span class="hljs-string">'http://localhost:8086'</span>
token = os.environ[<span class="hljs-string">'INFLUX_TOKEN'</span>] <span class="hljs-keyword">or</span> <span class="hljs-string">"&lt;token&gt;"</span>
org = os.environ[<span class="hljs-string">'INFLUX_ORG'</span>] <span class="hljs-keyword">or</span> <span class="hljs-string">'pmoritzer'</span>
</div></code></pre>
<p>Following that, a function will be defined to parse each row of the CSV containing the bird migration data. The following fields are used for this analysis:</p>
<ul>
<li>timestamp</li>
<li>event-id</li>
<li>lon</li>
<li>lat</li>
<li>manually-marked-outlier</li>
<li>individual-taxon-canonical-name</li>
<li>tag-local-identifier</li>
<li>individual-local-identifier</li>
</ul>
<p>The remaining columns have little value for this data analysis, so they are not considered in this project. The InfluxDB interface's Point-Object is returned by the following function. To create the dynamic data structure, we can use the provided Builder-Pattern. Each Point will later be stored as a dataset in an InfluxDB bucket.</p>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_row</span><span class="hljs-params">(row: OrderedDict)</span>:</span>   
    
    <span class="hljs-keyword">return</span> Point(<span class="hljs-string">"migration-point"</span>).tag(<span class="hljs-string">"type"</span>, <span class="hljs-string">"migration-value"</span>).measurement(<span class="hljs-string">"migration"</span>) \
        .field(<span class="hljs-string">"event-id"</span>, row[<span class="hljs-string">'event-id'</span>]) \
        .field(<span class="hljs-string">"lon"</span>, Decimal(row[<span class="hljs-string">'location-long'</span>])) \
        .field(<span class="hljs-string">"lat"</span>, Decimal(row[<span class="hljs-string">'location-lat'</span>])) \
        .field(<span class="hljs-string">"manually-marked-outlier"</span>, row[<span class="hljs-string">'manually-marked-outlier'</span>]) \
        .field(<span class="hljs-string">"individual-taxon-canonical-name"</span>, row[<span class="hljs-string">'individual-taxon-canonical-name'</span>]) \
        .field(<span class="hljs-string">"tag-local-identifier"</span>, row[<span class="hljs-string">'tag-local-identifier'</span>]) \
        .field(<span class="hljs-string">"individual-local-identifier"</span>, row[<span class="hljs-string">'individual-local-identifier'</span>]) \
        .time(row[<span class="hljs-string">'timestamp'</span>])               

</div></code></pre>
<p>The function above is then called for each row of the csv file using functional programming. It must be ensured that the.csv dataset mentioned earlier is located in the project's root directory and is named <code>migration_original.csv</code>.</p>
<pre class="hljs"><code><div>data = rx \
    .from_iterable(DictReader(open(<span class="hljs-string">'migration_original.csv'</span>, <span class="hljs-string">'r'</span>))) \
    .pipe(operators.map(<span class="hljs-keyword">lambda</span> row: parse_row(row)))
</div></code></pre>
<p>The command above maps each row from the source data set to an Ordered Dictionary entry and parses it to a. Afterwards we are left with a dictionary that is readable by the InfluxDB data client.</p>
<blockquote>
<p>Example adapted from: https://github.com/influxdata/influxdb-client-python/blob/master/examples/import_data_set.py (visited: June 4th, 22:00)</p>
</blockquote>
<p>The code below establishes a connection to InfluxDB, creates a new bucket using the Bucket API, and writes data to InfluxBD using the Write API, all of which are provided by the Python library.</p>
<pre class="hljs"><code><div><span class="hljs-keyword">with</span> connect_to_influxdb(url, token, org) <span class="hljs-keyword">as</span> client:
    bucket_name = <span class="hljs-string">'bird-migration'</span>
    bucket_api = client.buckets_api()
    old_bucket = bucket_api.find_bucket_by_name(bucket_name=bucket_name)
    <span class="hljs-keyword">if</span> old_bucket:
        <span class="hljs-keyword">try</span>:
            bucket_api.delete_bucket(old_bucket)
        <span class="hljs-keyword">except</span>:
            exit()
    bucket = bucket_api.create_bucket(bucket_name=bucket_name, org=org)

    <span class="hljs-keyword">with</span> client.write_api(write_options=WriteOptions(batch_size=<span class="hljs-number">50000</span>, flush_interval=<span class="hljs-number">10000</span>)) <span class="hljs-keyword">as</span> write_api:        
        write_api.write(bucket=<span class="hljs-string">"bird-migration"</span>, record=data)

    query = <span class="hljs-string">'from(bucket:"bird-migration")'</span> \
            <span class="hljs-string">' |&gt; range(start: 0, stop: now())'</span>
    result = client.query_api().query(query=query)
    print()
    print(<span class="hljs-string">"=== results ==="</span>)
    print(result)
</div></code></pre>
<p>The results will be validated by committing the following flux query using the Python code:</p>
<pre class="hljs"><code><div>from(bucket:"bird-migration") |&gt; range(<span class="hljs-keyword">start</span>: <span class="hljs-number">0</span>, <span class="hljs-keyword">stop</span>: <span class="hljs-keyword">now</span>())
</div></code></pre>
<p>The same query can be run using the InfluxDB web client to see if the data is in the database. To do so, select the 'Data'-tab in the left sidebar and then the Buckets Tab in the resulting screen. The 'bird-migration' bucket can then be selected, and the Script Editor can be selected in the opening content window. After submitting the query, the raw data can be viewed in a table by selecting the 'Table' display.</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/influxdb-setup/test-select.png" alt="alt text"><em>Viewing imported data</em></p>
<h2 id="setting-up-grafana">Setting up Grafana</h2>
<p>To setup Grafana, <code>localhost:3000</code> has to be accessed. A login can be performed with following credentials:</p>
<p>User: <code>admin</code>, password: <code>admin</code></p>
<p>The creation of a new account can be skipped, or a new password can be set.</p>
<h3 id="defining-influxdb-as-a-data-source">Defining InfluxDB as a data source</h3>
<p>The data source tab from the left side menu has to be selected:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/grafana-setup/data-source-tab.png" alt="alt text"><em>Grafana defining a data source</em></p>
<p>The blue 'Add data source' button next to the search bar must then be pressed. InfluxDB should be chosen from the list that appears. To register the previously installed InfluxDB data source, the following settings must be made:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/grafana-setup/configure-influxdb-datasource.png" alt="alt text"><em>Grafana defining a data source</em></p>
<p>The Query Language should be <code>Flux</code>, and the URL should be <code>http://influxdb:8086</code>, as defined by the docker compose DNS-Resolution. Basic authentication is used, with the username <code>root</code> and password <code>password</code>. In the final section, enter the organization name from the Influx-Setup, which is <code>pmoritzer</code> in this case, the root's API token, and the default bucket, which is <code>bird-migration</code> in this case. The 'Save &amp; Test' button can be used to see if the connection works.</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/grafana-setup/grafana-connection-success.png" alt="alt text"><em>Grafana: successful creation of InfluxDB data source</em></p>
<h3 id="creating-a-dashboard">Creating a dashboard</h3>
<p>The data is then visualized using a dashboard, which is created in the following step. The Dashboard option in Grafana must be selected to create a dashboard, as shown in the screenshot below:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/grafana-setup/dashboard-entry.png" alt="alt text"><em>Grafana: Dashboard entry point</em></p>
<p>Then, by pressing 'New Dashboard,' a new dashboard should be created. In the next step, a new panel can be added to the new dashboard and used to visualize data.</p>
<h2 id="visualizing-and-analyising-the-data">Visualizing and analyising the data</h2>
<h3 id="dashboard-variables">Dashboard variables</h3>
<p>The dataset contains 48 bird identifiers that should be filterable. A dashboard variable will be created to make this available. The gear symbol in the upper right corner must be selected, and the 'Variables' tab in the left sidebar must be accessed and a new variable created by clicking the 'New' button in the resulting window. The new variable should be named <code>localIdentifier</code> and should be derived from the type query. It is attempted to filter individual identifier names from the entire data set in order to obtain one entry for each bird in order to distinguish the birds as a variable. InfluxDB is queried by selecting the previously created data source. The following query must be entered in the text field:</p>
<pre class="hljs"><code><div>from(bucket:"bird-migration")
  |&gt; range(<span class="hljs-keyword">start</span>: <span class="hljs-number">0</span>, <span class="hljs-keyword">stop</span>: <span class="hljs-keyword">now</span>())
  |&gt; filter(fn: (r) =&gt;
    r._measurement == <span class="hljs-string">"migration"</span> <span class="hljs-keyword">and</span>
    r._field == <span class="hljs-string">"individual-local-identifier"</span>
  )

|&gt; <span class="hljs-keyword">keep</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"_value"</span>])
|&gt; <span class="hljs-keyword">distinct</span>(<span class="hljs-keyword">column</span>: <span class="hljs-string">"_value"</span>)
</div></code></pre>
<p>This Flux query selects all records and keeps only unique identifiers. The 'Multi-value' and 'Include All Option' options should be chosen. The overall configuration should now look like this:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/visualization/dashboard-variable.png" alt="alt text"><em>Visualization: Creating a Dashboard variable</em></p>
<p>After saving the variable and returning to the panel to be edited or the dashboard overview, variables can be selected from a dropdown menu. The queries must be fitted appropriately, which will occur when querying the data for visualization in the following steps.</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/visualization/dashboard-variable-2.png" alt="alt text"></p>
<p><em>Visualization: Dashboard variable after successful querying</em></p>
<h3 id="geomap--heatmap">Geomap &amp; Heatmap</h3>
<p>The configuration steps are numbered in the screenshot below and will be explained further down. The goal of this visualization is to show the location of each bird on a Geomap using the dataset's latitude and longitude.</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/visualization/geomap-1.png" alt="alt text"></p>
<p><em>Geomap: Configuration steps</em></p>
<ul>
<li>
<p>1: GeoMap must be chosen from the dropdown menu. The panel's display should now be a map.</p>
</li>
<li>
<p>2: The query is edited in the panel below. As a data source, InfluxDB should be selected as previously configured. It is critical to set the threshold to a larger data set for query options; in this example, it is set to the maximum value; otherwise, the query will not work for large time windows.</p>
</li>
<li>
<p>3: Now, follwing Flux query should be created:</p>
<pre class="hljs"><code><div>from(bucket: "bird-migration")
|&gt; range(<span class="hljs-keyword">start</span>: v.timeRangeStart, <span class="hljs-keyword">stop</span>: v.timeRangeStop)
|&gt; filter(fn: (r) =&gt; r._measurement == <span class="hljs-string">"migration"</span>)
|&gt; filter(fn: (r) =&gt; (r._field == <span class="hljs-string">"lat"</span>) <span class="hljs-keyword">or</span>  (r._field == <span class="hljs-string">"lon"</span>) <span class="hljs-keyword">or</span> (r._field == <span class="hljs-string">"individual-local-identifier"</span>))  
|&gt; <span class="hljs-keyword">pivot</span>(rowKey:[<span class="hljs-string">"_time"</span>], columnKey: [<span class="hljs-string">"_field"</span>], valueColumn: <span class="hljs-string">"_value"</span>)

|&gt; filter(fn: (r) =&gt; contains(<span class="hljs-keyword">value</span>: r[<span class="hljs-string">"individual-local-identifier"</span>], <span class="hljs-keyword">set</span>: ${localIdentifier:<span class="hljs-keyword">json</span>}))
</div></code></pre>
<p>This query selects the required location data using the <code>individual-local-identifier</code>, which the application can filter using the dashboard variables. Then, using <code>set: $localIdentifier:json</code>, it pivots the table to usable fields and filters after the dashboard variable currently selected, which is 'All' by default. The values for the ranges <code>v.timeRangeStart</code> and <code>v.timeRangeStop</code> come from the Grafana time window at the top of the panel.</p>
</li>
<li>
<p>4: A name for the panel options can be entered. The latitude and longitude fields may need to be selected from the dropdown menu. The data should already be displayed on the map at this point, but because each bird is the same color, it is difficult to distinguish them.</p>
</li>
<li>
<p>5&amp;6: A new <code>B</code> query should be added. It is associating the bird's unique identifier with a specific color. Because time series are not well suited to key value mappings, a workaround is used by merging the tables using an unusual Flux query and integrating CSV-Values. For this purpose, a relational database or a KeyValue-based database may be preferable:</p>
<pre class="hljs"><code><div>import "csv"

identifier = from(bucket:"bird-migration")
|&gt; range(<span class="hljs-keyword">start</span>: <span class="hljs-number">0</span>, <span class="hljs-keyword">stop</span>: <span class="hljs-keyword">now</span>())  
|&gt; filter(fn: (r) =&gt;
    r._measurement == <span class="hljs-string">"migration"</span> <span class="hljs-keyword">and</span>
    r._field == <span class="hljs-string">"individual-local-identifier"</span>
  )
|&gt; <span class="hljs-keyword">distinct</span>(<span class="hljs-keyword">column</span>: <span class="hljs-string">"_value"</span>) 
|&gt; <span class="hljs-keyword">rename</span>(<span class="hljs-keyword">columns</span>: {_value: <span class="hljs-string">"identifier"</span>}) 
|&gt; findColumn(
    fn: (<span class="hljs-keyword">key</span>) =&gt; key._measurement == <span class="hljs-string">"migration"</span>,
    <span class="hljs-keyword">column</span>: <span class="hljs-string">"identifier"</span>,
) 

csvData = <span class="hljs-string">"
id,color
0,#00fa9a
1,#dc143c
2,#00ffff
3,#00bfff
4,#f4a460
5,#9370db
6,#0000ff
7,#a020f0
8,#adff2f
9,#da70d6
10,#b0c4de
11,#ff00ff
12,#1e90ff
13,#f0e68c
14,#fa8072
15,#dda0dd
16,#ff1493
17,#afeeee
18,#98fb98
19,#7fffd4
20,#fafad2
21,#ff69b4
22,#ffb6c1
23,#fff015
24,#8fbc8f
25,#800800
26,#b03060
27,#d2b48c
28,#ff0000
29,#ffa500
30,#ffd700
31,#ffff00
32,#00ff00
33,#3cb371
34,#b8860b
35,#4682b4
36,#d2691e
37,#9acd32
38,#20b2aa
39,#00008b
40,#32cd32
41,#808080
42,#2f4f4f
43,#556b2f
44,#8b4513
45,#006400
46,#8b0000
47,#808000
48,#483d8b
"</span>

colors = csv.from(
    csv: csvData, <span class="hljs-keyword">mode</span>: <span class="hljs-string">"raw"</span>
)
|&gt; <span class="hljs-keyword">map</span>(fn: (r) =&gt; ({r <span class="hljs-keyword">with</span> color: r[<span class="hljs-string">"color"</span>], tag: r[<span class="hljs-string">"tag"</span>], <span class="hljs-string">"unique-local-identifier"</span>: <span class="hljs-keyword">if</span> <span class="hljs-built_in">int</span>(v: r[<span class="hljs-string">"id"</span>]) &lt; <span class="hljs-keyword">length</span>(arr: identifier) <span class="hljs-keyword">then</span> identifier[<span class="hljs-built_in">int</span>(v: r[<span class="hljs-string">"id"</span>])] <span class="hljs-keyword">else</span> <span class="hljs-string">"no color"</span>}))
|&gt; <span class="hljs-keyword">drop</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"id"</span>])
|&gt; yield()
</div></code></pre>
<p>A Transform can be added from the results of this query by clicking on the 'Transform' tab next to the 'Query' tab. It is necessary to include the transformation 'Config from query results'. Config query <code>B</code> should apply to <code>fields with name</code> and options <code>individual-local-identifier (base field name)</code>. The values for the field color should be <code>Use as: Value mappings / Color</code> and <code>Select: All Values</code>, while the values for the field <code>unique-local-identifier</code> should be <code>Use as: Value mappings / Value</code> and <code>Select: All Values</code>. By mapping each value to a color and coloring the data points in the map for each distinct <code>local-identifier</code>, each bird should be distinguishable on the map. The following screenshot shows the transformation in its entirety:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/visualization/geomap-2.png" alt="alt text"></p>
<p><em>Geomap: Color Mapping Transform</em></p>
</li>
</ul>
<p>A new panel is created for the heatmap. The query's data source is <code> Dashboard --</code> because the same data as in the geomap is used. <code>Use results from panel: Geomap</code> should be selected from the dropdown menu. 'Heatmap' should now be applied to the layer options in 4. A heatmap is created by reusing data from the first panel's queries. The following is the configuration:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/visualization/heatmap.png" alt="alt text"></p>
<p><em>Heatmap</em></p>
<p>The visualization results should now look like this. Individual identifiers can be filtered in a specific time slot. The data ranges from 2009 to 2015, so a little experimenting can be done. Most birds, as expected, spend the summer in the northern hemisphere and migrate south in the winter. This phenomenon can be retraced by setting time values.</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/visualization/heatmap-geomap.png" alt="alt text"></p>
<p><em>Results of the Geomap and Heatmap visualization</em></p>
<h3 id="latitude-over-time">Latitude over time</h3>
<p>The latitude should then be visualized over time. Because birds migrate back and forth over the seasons, the expected data should be similar to a sine/cosine function.</p>
<p>A new panel with two Flux-queries should be created. Instead of Geomap, choose 'Time Series' from the list. Everything on the right side can be customized to one's liking. Only the line interpolation is changed for this visualization to create a smoother curve. As the <code>A</code> query is used, the following query is used:</p>
<pre class="hljs"><code><div>from(bucket: "bird-migration")
|&gt; range(<span class="hljs-keyword">start</span>: v.timeRangeStart, <span class="hljs-keyword">stop</span>: v.timeRangeStop)
|&gt; filter(fn: (r) =&gt; r._measurement == <span class="hljs-string">"migration"</span>)
|&gt; filter(fn: (r) =&gt; (r._field == <span class="hljs-string">"lat"</span>) <span class="hljs-keyword">or</span> (r._field == <span class="hljs-string">"individual-local-identifier"</span>))  
|&gt; <span class="hljs-keyword">pivot</span>(rowKey: [<span class="hljs-string">"_time"</span>], columnKey: [<span class="hljs-string">"_field"</span>], valueColumn: <span class="hljs-string">"_value"</span>)
|&gt; filter(fn: (r) =&gt; contains(<span class="hljs-keyword">value</span>: r[<span class="hljs-string">"individual-local-identifier"</span>], <span class="hljs-keyword">set</span>: ${localIdentifier:<span class="hljs-keyword">json</span>}))
|&gt; <span class="hljs-keyword">pivot</span>(rowKey: [<span class="hljs-string">"_time"</span>], columnKey: [<span class="hljs-string">"individual-local-identifier"</span>], valueColumn: <span class="hljs-string">"lat"</span>)
</div></code></pre>
<p>Again the results can be filtered by time and the local identifier. For the color of the time series the same query and transform as before is used for <code>B</code>, it can just be copied over.</p>
<p>The whole configuration and the result can be viewed in the following picture:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/visualization/latitude-complete.png" alt="alt text"></p>
<p><em>Results of the latitude over time visualization</em></p>
<h3 id="classification">Classification</h3>
<p>This classification's goal is to create a classification using Naive Bayes. The primary objective is to forecast the season based on training data.</p>
<p>$$ P(season | location) $$</p>
<p>Pre-processing is required first. To make things clear, the time will be divided into four seasons (winter, spring, summer, and autumn), and the locations will be mapped to climate zones as follows:</p>
<table>
<thead>
<tr>
<th><strong>Months</strong></th>
<th><strong>Season</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>12-02</td>
<td>Winter</td>
</tr>
<tr>
<td>03-05</td>
<td>Spring</td>
</tr>
<tr>
<td>06-08</td>
<td>Summer</td>
</tr>
<tr>
<td>09-11</td>
<td>Autumn</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Latitude</strong></td>
<td><strong>Location</strong></td>
</tr>
<tr>
<td>60-90</td>
<td>Cold</td>
</tr>
<tr>
<td>40-60</td>
<td>Mild</td>
</tr>
<tr>
<td>23.5-40</td>
<td>Subtropical</td>
</tr>
<tr>
<td>0-23.5</td>
<td>Tropical</td>
</tr>
</tbody>
</table>
<p>(Taken from: https://content.meteoblue.com/en/meteoscool/general-climate-zones [visited: 14.07.2022, 22:40])</p>
<p>The training data is then transferred to a binary table in the following manner:</p>
<table>
<thead>
<tr>
<th></th>
<th>tropical</th>
<th>subtropical</th>
<th>mild</th>
<th>cold</th>
</tr>
</thead>
<tbody>
<tr>
<td>winter</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>summer</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>autumn</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>autumn</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>winter</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>summer</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>spring</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>A new panel has to be created on the existing Grafana dashboard with a Table as visulization option and an InfluxDB as a data source. Following query will built the table displayed above:</p>
<pre class="hljs"><code><div>import "date"

from(bucket: "bird-migration")
|&gt; range(<span class="hljs-keyword">start</span>: v.timeRangeStart, <span class="hljs-keyword">stop</span>: v.timeRangeStop)
|&gt; filter(fn: (r) =&gt; (r._field == <span class="hljs-string">"lat"</span>))  
|&gt; <span class="hljs-keyword">pivot</span>(rowKey: [<span class="hljs-string">"_time"</span>], columnKey: [<span class="hljs-string">"_field"</span>], valueColumn: <span class="hljs-string">"_value"</span>)
|&gt; <span class="hljs-keyword">map</span>(fn: (r) =&gt; ({
  tropical:       
    <span class="hljs-keyword">if</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"lat"</span>] &lt; <span class="hljs-number">23.5</span> <span class="hljs-keyword">then</span>
      <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
  subtropical:
    <span class="hljs-keyword">if</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">23.5</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"lat"</span>] &lt; <span class="hljs-number">40</span> <span class="hljs-keyword">then</span>
      <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
  mild:
    <span class="hljs-keyword">if</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">40</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"lat"</span>] &lt; <span class="hljs-number">60</span> <span class="hljs-keyword">then</span>
      <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
  cold:
    <span class="hljs-keyword">if</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">40</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">60</span> <span class="hljs-keyword">then</span>
      <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
  _season: 
    <span class="hljs-keyword">if</span> date.month(t: r._time) == <span class="hljs-number">12</span> <span class="hljs-keyword">or</span> date.month(t: r._time) &lt;= <span class="hljs-number">2</span> <span class="hljs-keyword">then</span> 
      <span class="hljs-string">"winter"</span>
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> date.month(t: r._time) &gt;= <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> date.month(t: r._time) &lt;= <span class="hljs-number">5</span> <span class="hljs-keyword">then</span> 
      <span class="hljs-string">"spring"</span>
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> date.month(t: r._time) &gt;= <span class="hljs-number">6</span> <span class="hljs-keyword">and</span> date.month(t: r._time) &lt;= <span class="hljs-number">8</span> <span class="hljs-keyword">then</span> 
      <span class="hljs-string">"summer"</span>
    <span class="hljs-keyword">else</span> 
      <span class="hljs-string">"autumn"</span>
  }))

</div></code></pre>
<p>The data will be kept in this panel and a new panel will be created in the dashboard to create a probability table based on the Bayes' theorem. The table should now look like this:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/classification/binary-table.png" alt="alt text"></p>
<p><em>Binary table for classification</em></p>
<p>Considering the Bayes theorem with following example, these assumptions can be made. The climate zone 'tropes' is choosen as a field and calculate the probability of it being winter (class). This is going to be done for every field.</p>
<table>
<thead>
<tr>
<th><strong>Result</strong></th>
<th><strong>Formula</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>P(winter|tropes)</td>
<td>(P(winter) * P(tropes|winter)) / P(tropes)</td>
</tr>
<tr>
<td>P(winter)</td>
<td>winter_season_entries / all_entries</td>
</tr>
<tr>
<td>P(tropes)</td>
<td>tropes_entries / all_entries</td>
</tr>
<tr>
<td>P(tropes | winter)</td>
<td>tropes_in_winter / winter_season_entries</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Example Data</strong></td>
<td></td>
</tr>
<tr>
<td>all_entries</td>
<td>50</td>
</tr>
<tr>
<td>winter_season_entries</td>
<td>17</td>
</tr>
<tr>
<td>tropes_entries</td>
<td>20</td>
</tr>
<tr>
<td>tropes_in_winter</td>
<td>18</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Example Calculation</strong></td>
<td></td>
</tr>
<tr>
<td>P(winter)</td>
<td>17/50 = 0.34</td>
</tr>
<tr>
<td>P(tropes)</td>
<td>20/50 = 0.4</td>
</tr>
<tr>
<td>P(tropes | winter)</td>
<td>18/20 = 0.9</td>
</tr>
<tr>
<td>P(winter | tropes)</td>
<td><strong>(0.34 * 0.9) / 0.4 = 0.765 = 76.5%</strong></td>
</tr>
</tbody>
</table>
<p>Which means: If an entry is in the tropes, it can be said with a certainty of 76.5% that the current season is winter. This example will be transferred to every class-field combination to make sure a statement can be made about every entry and this will be the final Naive Bayes classifier.</p>
<p>By extending the flux query in a new panel a probability table will that should contain all the values needed for the calculation.
The following flux query will be run first to count the values and union them into a single table.</p>
<blockquote>
<p>Note: The query is pretty complex since the mapping is done manually in most part. A better preprocessing using Python or some more abstraction in Flux might make this easier. But it still outputs the right data for the classification problem.</p>
</blockquote>
<pre class="hljs"><code><div>import "date"
import "array"

training_data = from(bucket: "bird-migration")
|&gt; range(<span class="hljs-keyword">start</span>: v.timeRangeStart, <span class="hljs-keyword">stop</span>: v.timeRangeStop)
|&gt; filter(fn: (r) =&gt; (r._field == <span class="hljs-string">"lat"</span>))  
|&gt; <span class="hljs-keyword">pivot</span>(rowKey: [<span class="hljs-string">"_time"</span>], columnKey: [<span class="hljs-string">"_field"</span>], valueColumn: <span class="hljs-string">"_value"</span>)
|&gt; <span class="hljs-keyword">map</span>(fn: (r) =&gt; ({
  tropical:       
    <span class="hljs-keyword">if</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"lat"</span>] &lt; <span class="hljs-number">23.5</span> <span class="hljs-keyword">then</span>
      <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
  subtropical:
    <span class="hljs-keyword">if</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">23.5</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"lat"</span>] &lt; <span class="hljs-number">40</span> <span class="hljs-keyword">then</span>
      <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
  mild:
    <span class="hljs-keyword">if</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">40</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"lat"</span>] &lt; <span class="hljs-number">60</span> <span class="hljs-keyword">then</span>
      <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
  cold:
    <span class="hljs-keyword">if</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">40</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"lat"</span>] &gt;= <span class="hljs-number">60</span> <span class="hljs-keyword">then</span>
      <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>,
  _season: 
    <span class="hljs-keyword">if</span> date.month(t: r._time) == <span class="hljs-number">12</span> <span class="hljs-keyword">or</span> date.month(t: r._time) &lt;= <span class="hljs-number">2</span> <span class="hljs-keyword">then</span> 
      <span class="hljs-string">"winter"</span>
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> date.month(t: r._time) &gt;= <span class="hljs-number">3</span> <span class="hljs-keyword">and</span> date.month(t: r._time) &lt;= <span class="hljs-number">5</span> <span class="hljs-keyword">then</span> 
      <span class="hljs-string">"spring"</span>
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> date.month(t: r._time) &gt;= <span class="hljs-number">6</span> <span class="hljs-keyword">and</span> date.month(t: r._time) &lt;= <span class="hljs-number">8</span> <span class="hljs-keyword">then</span> 
      <span class="hljs-string">"summer"</span>
    <span class="hljs-keyword">else</span> 
      <span class="hljs-string">"autumn"</span>
  }))

all_entries = training_data |&gt; reduce(
        fn: (r, accumulator) =&gt; ({all_entries: accumulator.all_entries + <span class="hljs-number">1</span> }),
        <span class="hljs-keyword">identity</span>: {all_entries: <span class="hljs-number">0</span>}, 
    ) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

winter_season_entries = training_data |&gt; reduce(
        fn: (r, accumulator) =&gt; ({winter_season_entries: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_season"</span>] == <span class="hljs-string">"winter"</span> <span class="hljs-keyword">then</span> accumulator.winter_season_entries + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> accumulator.winter_season_entries + <span class="hljs-number">0</span> }),
        <span class="hljs-keyword">identity</span>: {winter_season_entries: <span class="hljs-number">0</span>}, 
    ) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

spring_season_entries = training_data |&gt; reduce(
        fn: (r, accumulator) =&gt; ({spring_season_entries: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_season"</span>] == <span class="hljs-string">"spring"</span> <span class="hljs-keyword">then</span> accumulator.spring_season_entries + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> accumulator.spring_season_entries + <span class="hljs-number">0</span> }),
        <span class="hljs-keyword">identity</span>: {spring_season_entries: <span class="hljs-number">0</span>}, 
    ) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

summer_season_entries = training_data |&gt; reduce(
        fn: (r, accumulator) =&gt; ({summer_season_entries: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_season"</span>] == <span class="hljs-string">"summer"</span> <span class="hljs-keyword">then</span> accumulator.summer_season_entries + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> accumulator.summer_season_entries + <span class="hljs-number">0</span> }),
        <span class="hljs-keyword">identity</span>: {summer_season_entries: <span class="hljs-number">0</span>}, 
    ) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])
autumn_season_entries = training_data |&gt; reduce(
        fn: (r, accumulator) =&gt; ({autumn_season_entries: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_season"</span>] == <span class="hljs-string">"autumn"</span> <span class="hljs-keyword">then</span> accumulator.autumn_season_entries + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> accumulator.autumn_season_entries + <span class="hljs-number">0</span> }),
        <span class="hljs-keyword">identity</span>: {autumn_season_entries: <span class="hljs-number">0</span>}, 
    ) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

tropical_entries = training_data |&gt; reduce(fn: (r, accumulator) =&gt; ({tropical_entries: r[<span class="hljs-string">"tropical"</span>] + accumulator.tropical_entries}), <span class="hljs-keyword">identity</span>: {tropical_entries: <span class="hljs-number">0</span>})
        |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

subtropical_entries = training_data |&gt; reduce(fn: (r, accumulator) =&gt; ({subtropical_entries: r[<span class="hljs-string">"subtropical"</span>] + accumulator.subtropical_entries}), <span class="hljs-keyword">identity</span>: {subtropical_entries: <span class="hljs-number">0</span>})
        |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

mild_entries = training_data |&gt; reduce(fn: (r, accumulator) =&gt; ({mild_entries: r[<span class="hljs-string">"mild"</span>] + accumulator.mild_entries}), <span class="hljs-keyword">identity</span>: {mild_entries: <span class="hljs-number">0</span>})
        |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

cold_entries = training_data |&gt; reduce(fn: (r, accumulator) =&gt; ({cold_entries: r[<span class="hljs-string">"cold"</span>] + accumulator.cold_entries}), <span class="hljs-keyword">identity</span>: {cold_entries: <span class="hljs-number">0</span>})
        |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

combined_1 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: winter_season_entries, t2: spring_season_entries}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>])
combined_2 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: combined_1, t2: summer_season_entries}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>])
combined_3 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: combined_2, t2: autumn_season_entries}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>]) 
combined_4 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: combined_3, t2: tropical_entries}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>]) 
combined_5 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: combined_4, t2: subtropical_entries}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>]) 
combined_6 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: combined_5, t2: mild_entries}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>]) 
combined_7 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: combined_6, t2: cold_entries}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>]) 
count_entries = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: combined_7, t2: all_entries}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>])

<span class="hljs-keyword">rows</span> = [
  {_class: <span class="hljs-string">"winter"</span>, _field: <span class="hljs-string">"tropical"</span>},
  {_class: <span class="hljs-string">"winter"</span>, _field: <span class="hljs-string">"subtropical"</span>},
  {_class: <span class="hljs-string">"winter"</span>, _field: <span class="hljs-string">"mild"</span>},
  {_class: <span class="hljs-string">"winter"</span>, _field: <span class="hljs-string">"cold"</span>},

  {_class: <span class="hljs-string">"spring"</span>, _field: <span class="hljs-string">"tropical"</span>},
  {_class: <span class="hljs-string">"spring"</span>, _field: <span class="hljs-string">"subtropical"</span>},
  {_class: <span class="hljs-string">"spring"</span>, _field: <span class="hljs-string">"mild"</span>},
  {_class: <span class="hljs-string">"spring"</span>, _field: <span class="hljs-string">"cold"</span>},

  {_class: <span class="hljs-string">"summer"</span>, _field: <span class="hljs-string">"tropical"</span>},
  {_class: <span class="hljs-string">"summer"</span>, _field: <span class="hljs-string">"subtropical"</span>},
  {_class: <span class="hljs-string">"summer"</span>, _field: <span class="hljs-string">"mild"</span>},
  {_class: <span class="hljs-string">"summer"</span>, _field: <span class="hljs-string">"cold"</span>},

  {_class: <span class="hljs-string">"autumn"</span>, _field: <span class="hljs-string">"tropical"</span>},
  {_class: <span class="hljs-string">"autumn"</span>, _field: <span class="hljs-string">"subtropical"</span>},
  {_class: <span class="hljs-string">"autumn"</span>, _field: <span class="hljs-string">"mild"</span>},
  {_class: <span class="hljs-string">"autumn"</span>, _field: <span class="hljs-string">"cold"</span>},
]
  
class_field_mapping = array.from(<span class="hljs-keyword">rows</span>: <span class="hljs-keyword">rows</span>) 
        |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>)
        |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

class_field_count_total = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: count_entries, t2: class_field_mapping}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>]) 

count_fields_by_class = (<span class="hljs-keyword">tables</span>=&lt;-, <span class="hljs-keyword">class</span>) =&gt; <span class="hljs-keyword">tables</span>
    |&gt; reduce(
        <span class="hljs-keyword">identity</span>: {
            sum_cold: <span class="hljs-number">0</span>,
            sum_mild: <span class="hljs-number">0</span>,
            sum_subtropical: <span class="hljs-number">0</span>,
            sum_tropical: <span class="hljs-number">0</span>,
        },
        fn: (r, accumulator) =&gt; ({
          sum_tropical: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_season"</span>] == <span class="hljs-keyword">class</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"tropical"</span>] == <span class="hljs-number">1</span> <span class="hljs-keyword">then</span> accumulator.sum_tropical + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> accumulator.sum_tropical + <span class="hljs-number">0</span>,
          sum_subtropical: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_season"</span>] == <span class="hljs-keyword">class</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"subtropical"</span>] == <span class="hljs-number">1</span> <span class="hljs-keyword">then</span> accumulator.sum_subtropical + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> accumulator.sum_subtropical + <span class="hljs-number">0</span>,
          sum_mild: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_season"</span>] == <span class="hljs-keyword">class</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"mild"</span>] == <span class="hljs-number">1</span> <span class="hljs-keyword">then</span> accumulator.sum_mild + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> accumulator.sum_mild + <span class="hljs-number">0</span>,
          sum_cold: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_season"</span>] == <span class="hljs-keyword">class</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"cold"</span>] == <span class="hljs-number">1</span> <span class="hljs-keyword">then</span> accumulator.sum_cold + <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> accumulator.sum_cold + <span class="hljs-number">0</span>,
        }),
    )

field_while_class_winter = training_data |&gt; count_fields_by_class(<span class="hljs-keyword">class</span>: <span class="hljs-string">"winter"</span>) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>) |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])
field_while_class_spring = training_data |&gt; count_fields_by_class(<span class="hljs-keyword">class</span>: <span class="hljs-string">"spring"</span>) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>) |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])
field_while_class_summer = training_data |&gt; count_fields_by_class(<span class="hljs-keyword">class</span>: <span class="hljs-string">"summer"</span>) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>) |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])
field_while_class_autumn = training_data |&gt; count_fields_by_class(<span class="hljs-keyword">class</span>: <span class="hljs-string">"autumn"</span>) |&gt; <span class="hljs-keyword">set</span>(<span class="hljs-keyword">key</span>: <span class="hljs-string">"tag"</span>, <span class="hljs-keyword">value</span>: <span class="hljs-string">""</span>) |&gt; <span class="hljs-keyword">group</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"tag"</span>])

combined_field_class_1 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {winter: field_while_class_winter, spring: field_while_class_spring}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>])
combined_field_class_2 = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t3: combined_field_class_1, summer: field_while_class_summer}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>])
combined_field_class = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {summer: combined_field_class_2, autumn: field_while_class_autumn}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>]) 

temp_combined_field_class_count_total = <span class="hljs-keyword">join</span>(<span class="hljs-keyword">tables</span>: {t1: class_field_count_total, t2: combined_field_class}, <span class="hljs-keyword">on</span>: [<span class="hljs-string">"tag"</span>]) 

mapped_calc_values = temp_combined_field_class_count_total |&gt; <span class="hljs-keyword">map</span>(fn: (r) =&gt; ({
    r <span class="hljs-keyword">with</span> field_in_class_count: <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"winter"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"tropical"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_tropical_winter"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"winter"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"subtropical"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_subtropical_winter"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"winter"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"mild"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_mild_winter"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"winter"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"cold"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_cold_winter"</span>]

    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"spring"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"tropical"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_tropical_spring"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"spring"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"subtropical"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_subtropical_spring"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"spring"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"mild"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_mild_spring"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"spring"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"cold"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_cold_spring"</span>]

    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"summer"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"tropical"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_tropical_summer"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"summer"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"subtropical"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_subtropical_summer"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"summer"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"mild"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_mild_summer"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"summer"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"cold"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_cold_summer"</span>]

    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"autumn"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"tropical"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_tropical_autumn"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"autumn"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"subtropical"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_subtropical_autumn"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"autumn"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"mild"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_mild_autumn"</span>]
    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> r[<span class="hljs-string">"_class"</span>] == <span class="hljs-string">"autumn"</span> <span class="hljs-keyword">and</span> r[<span class="hljs-string">"_field"</span>] == <span class="hljs-string">"cold"</span> <span class="hljs-keyword">then</span> r[<span class="hljs-string">"sum_cold_autumn"</span>]

    <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>    
})) |&gt; <span class="hljs-keyword">drop</span>(<span class="hljs-keyword">columns</span>: [<span class="hljs-string">"sum_tropical_winter"</span>,<span class="hljs-string">"sum_subtropical_winter"</span>,<span class="hljs-string">"sum_mild_winter"</span>,<span class="hljs-string">"sum_cold_winter"</span>,<span class="hljs-string">"sum_tropical_spring"</span>,<span class="hljs-string">"sum_subtropical_spring"</span>,<span class="hljs-string">"sum_mild_spring"</span>,<span class="hljs-string">"sum_cold_spring"</span>,
<span class="hljs-string">"sum_tropical_summer"</span>,<span class="hljs-string">"sum_subtropical_summer"</span>,<span class="hljs-string">"sum_mild_summer"</span>,<span class="hljs-string">"sum_cold_summer"</span>,<span class="hljs-string">"sum_tropical_autumn"</span>,<span class="hljs-string">"sum_subtropical_autumn"</span>,<span class="hljs-string">"sum_mild_autumn"</span>,<span class="hljs-string">"sum_cold_autumn"</span>])
</div></code></pre>
<p>Following the successful execution of this query, every value required for the calculation shown above is listed in the table below:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/classification/count-table.png" alt="alt text"></p>
<p><em>Count table as intermediate step</em></p>
<p>To complete the described classifier, the final step is to calculate the table shown below.</p>
<table>
<thead>
<tr>
<th>Class</th>
<th>Field</th>
<th>p_class</th>
<th>p_field</th>
<th>p_field_class</th>
<th>Probability</th>
</tr>
</thead>
<tbody>
<tr>
<td>winter</td>
<td>tropes</td>
<td>0.34</td>
<td>0.4</td>
<td>0.9</td>
<td>0.765</td>
</tr>
<tr>
<td>winter</td>
<td>mild</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
<tr>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
<tr>
<td>summer</td>
<td>cold</td>
<td>..</td>
<td>..</td>
<td>..</td>
<td>..</td>
</tr>
</tbody>
</table>
<p>By creating a new panel and adding these lines to the existing flux query the table should be calculated correctly:</p>
<pre class="hljs"><code><div>mapped_calc_values |&gt; map(fn: (r) =&gt; ({_class: r["_class"], _field: r["_field"],
p_class: 
  if r["_class"] == "winter" then float(v: r["winter_season_entries"])/float(v: r["all_entries"])
  else if r["_class"] == "spring" then float(v: r["spring_season_entries"])/float(v: r["all_entries"])
  else if r["_class"] == "summer" then float(v: r["summer_season_entries"])/float(v: r["all_entries"])
  else if r["_class"] == "autumn" then float(v: r["autumn_season_entries"])/float(v: r["all_entries"])
  else 0.0,
p_field:
  if r["_field"] == "tropical" then float(v: r["tropical_entries"])/float(v: r["all_entries"])
  else if r["_field"] == "subtropical" then float(v: r["subtropical_entries"])/float(v: r["all_entries"])
  else if r["_field"] == "mild" then float(v: r["mild_entries"])/float(v: r["all_entries"])
  else if r["_field"] == "cold" then float(v: r["cold_entries"])/float(v: r["all_entries"])
  else 0.0,
p_field_class: 
  if r["_class"] == "winter" then float(v: r["field_in_class_count"])/float(v: r["winter_season_entries"])
  else if r["_class"] == "spring" then float(v: r["field_in_class_count"])/float(v: r["spring_season_entries"])
  else if r["_class"] == "summer" then float(v: r["field_in_class_count"])/float(v: r["summer_season_entries"])
  else if r["_class"] == "autumn" then float(v: r["field_in_class_count"])/float(v: r["autumn_season_entries"])
  else 0.0,
}))
|&gt; map(fn: (r) =&gt; ({r <span class="hljs-keyword">with</span> probability: (r[<span class="hljs-string">"p_class"</span>]*r[<span class="hljs-string">"p_field_class"</span>]) / r[<span class="hljs-string">"p_field"</span>] }))
</div></code></pre>
<p>And the resulting trained classifier should be created and displayed in a table:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/classification/trained-classifier.png" alt="alt text"></p>
<p><em>Count table as intermediate step</em></p>
<p>Using the location of birds as a value, this type of classifier can predict which season is currently in effect with a degree of precision. Interesting data points include the fact that if a bird is in the cold zone of the earth, the current season is winter 70% of the time. There are no birds in the cold zone during the winter, so it is certain that if a bird is in the cold zone, it is not winter. Another expected result is that if a bird is in a tropical zone, it is most likely winter, but this can only be said with a certainty of 34.1 percent; rather, if a bird is in a subtropical zone, it is more likely to be winter with a certainty of 37.9 percent. The problem may be that the climate zones are not fine-grained enough for categorizing the position of the birds, particularly between the subtropicals and the tropicals.
This classifier takes the whole dataset as training data. By changing the time window it is possible to change the dataset and therefore to get a differently trained classifier.</p>
<h1 id="summary">Summary</h1>
<h2 id="result">Result</h2>
<p>The final dashboard should look as follows:</p>
<p><img src="file:///Users/philippmoritzer/Documents/Hochschule/Big Data &amp; Machine Learning/project/docs/images/visualization/full-dashboard.png" alt="alt text"></p>
<p><em>Count table as intermediate step</em></p>
<h2 id="conclusion">Conclusion</h2>
<p>InfluxDB is an excellent tool for dealing with large datasets of time series data. It is suitable for real-time analytics when combined with its Python library. The query language Flux is capable of performing extensive data analytics, as demonstrated by classification and visualization.</p>
<h2 id="outlook">Outlook</h2>
<p>This project takes a predefined dataset and processes it to InfluxDB in batches. Even though the queries would still work when streaming data, this project has not tested them. It could be an interesting approach to real-time analytics using InfluxDB and streaming data. Streaming IoT data from sensors to an Influx instance or even a distributed InfluxDB instance could be another interesting approach.</p>
<h2 id="repository-and-sample-project">Repository and sample project</h2>
<p>The whole source code can be found under the following GitHub repository:</p>
<p>Source Code Repository: https://github.com/philippmoritzer/bd-ml-project</p>
<p>If some step does not work or the project just wants to be tried, the project can be just checked out using git. After running <code>docker-compose up</code>, InfluxDB should be spun up on <code>localhost:8086</code> and Grafana sould be accessible on <code>localhost:3000</code>.</p>
<pre class="hljs"><code><div><span class="hljs-comment">#Login InfluxDB</span>
<span class="hljs-attr">user</span>=<span class="hljs-string">root</span>
<span class="hljs-attr">password</span>=<span class="hljs-string">password</span>
<span class="hljs-comment">
#Login Grafana</span>
<span class="hljs-attr">user</span>=<span class="hljs-string">admin</span>
<span class="hljs-attr">password</span>=<span class="hljs-string">admin</span>
</div></code></pre>
<h2 id="demo">Demo</h2>
<p>The whole project is hosted here:</p>
<p>Grafana: https://grafana.philippmoritzer.com/</p>
<p>InfluxDB: https://influx.philippmoritzer.com/</p>
<pre class="hljs"><code><div><span class="hljs-comment">#Login InfluxDB</span>
<span class="hljs-attr">user</span>=<span class="hljs-string">root</span>
<span class="hljs-attr">password</span>=<span class="hljs-string">bd-ml-2022</span>
<span class="hljs-comment">
#Login Grafana</span>
<span class="hljs-attr">user</span>=<span class="hljs-string">admin</span>
<span class="hljs-attr">password</span>=<span class="hljs-string">bd-ml-2022</span>
</div></code></pre>
<h1 id="sources">Sources</h1>
<ul>
<li>[1]   Brad Dayley. Sams Teach Yourself NoSQL with MongoDB in 24 Hours, Video Enhanced Edition. O'REILLY. 2014.</li>
<li>[2]   Kasun Idrasiri, Sriskandarajah Suhothayan. Design Patterns for Cloud Native Applications. O'REILLY. 2021.</li>
<li>[3]   CloudLab. NoSQL - CAP Theorem. Author unknown. Date unknown. URL: https://cloudxlab.com/assessment/displayslide/345/nosql-cap-theorem#:~:text=NoSQL%20can%20not%20provide%20consistency,Consistency%2C%20Availability%20and%20Partition%20Tolerance. (visited: 10.07.2022, 20:15)</li>
<li>[4]   Ted Dunning, Ellen Friedman. Time Series Databases: New Ways to Store and Access Data. O'REILLY. 2014.</li>
<li>[5]   Joe Reis, Matt Housley. Fundamentals of Data Engineering: Plan and Build Robust Data Systems. O'REILLYs. 2022.</li>
<li>[6]   Paul Dix. Why Build a Time Series Data Platform?. db-engines. 2017. https://db-engines.com/en/blog_post/71 (visited: 10.07.2022, 20:15)</li>
<li>[7]   Kovid Rathee. The case for using timeseries databases. 2021. URL: https://towardsdatascience.com/the-case-for-using-timeseries-databases-c060a8afe727 (visited: 10.07.2022, 20:15)</li>
<li>[8]   db-engines. InfluxDB System Properties. 2022. URL: https://db-engines.com/en/system/InfluxDB (visited: 10.07.2022, 20:15)</li>
<li>[9]   influxdata. influxdata - Documentation. 2022. URL: https://docs.influxdata.com/ (visited: 10.07.2022, 20:15)</li>
<li>[10]  influxdata. Get started with Flux. 2022. URL: https://docs.influxdata.com/influxdb/cloud/query-data/get-started/ (visited: 10.07.2022, 20:15)</li>
<li>[11]  Rohan Sreerama. A Deep Dive into Machine Learning in Flux: Naive Bayes Classification. 2020. URL: https://www.influxdata.com/blog/deep-dive-into-machine-learning-in-flux-naive-bayes-classification/ (visited: 10.07.2022, 20:15)</li>
<li>[12]  Igor Bobriakov. Prometheus vs InfluxDB. 2020. URL: https://www.metricfire.com/blog/prometheus-vs-influxdb/ (visited: 10.07.2022, 20:15)</li>
<li>[13]  db-engines. System Properties Comparison InfluxDB vs. Prometheus vs. TimescaleDB. 2022, URL: https://db-engines.com/en/system/InfluxDB%3BPrometheus%3BTimescaleDB (visited: 10.07.2022, 20:15)</li>
<li>[14]  United Manufacturing Hub. Why we chose timescaleDB over InfluxDB. 2022, URL: https://docs.umh.app/docs/concepts/timescaledb-vs-influxdb/</li>
<li>[15]  Team Magic. Building a Naive Bayes classifier using Flux. 2020. URL: https://github.com/RohanSreerama5/Naive-Bayes-Classifier-Flux/blob/master/Naive%20Bayes.pdf (visited: 10.07.2022, 20:15)</li>
<li>[16]  Rohan Sreerama. Naive-Bayes-Classifier-Flux. 2020. URL: https://github.com/RohanSreerama5/Naive-Bayes-Classifier-Flux (visited: 10.07.2022)</li>
</ul>

</body>
</html>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });</script>